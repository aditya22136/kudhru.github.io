---
layout: post
title: Deep Generative Stochastic Networks Trainable By Backprop
author: Jiaming Song
tags:
- reading
---

## Deep Generative Stochastic Networks Trainable By Backprop

>  Bengio et al. 2013. [https://arxiv.org/pdf/1306.1091v5.pdf](https://arxiv.org/pdf/1306.1091v5.pdf)

Generative Stochastic Networks aim to estimate the data generating distribution indirectly, by parametrizing the transition operator of a Markov chain rather than directly parametrizing $$p(x)$$.

> To evade the problem of highly multimodal joint or posterior distributions, the currently known approaches to dealing with the above intractable sums make very strong assumptions on the distribution of interest. In practice, however, the multimodality problem is encountered.

To evade the problem, another assumption is made: the effectiveness of function approximation.

In particular - GSN relies on estimating the transition operator of a Markov chain $$P(x_t \lvert x_{t-1})$$ or $$P(x_t, h_t \lvert x_{t-1}, h_{t-1})$$. Consider the denoising setting - given a clean data $$X$$, a corrupted version $$\tilde{X}$$ is obtained through $$C(\tilde{X}\lvert X)$$. Therefore, $$P(X)$$ and $$P(X \lvert \tilde{X})$$ can be reconstructed by each other given $$C(\tilde{X}\lvert X)$$. However, as $$P(X)$$ has many modes, while $$P(X \lvert \tilde{X})$$ has a few (because of the condition), it is easier to learn the latter. If we have a simple $$C$$, then the complexity in $$P(X\lvert \tilde{X})$$ is transferred to the mode dependency on $$\tilde{X}$$.

**Theorem 1** If $$P_{\theta_n}(X \lvert \tilde{X})$$ is a consistent estimator of the true conditional distribution $$P(X\lvert \tilde{X})$$ and $$T_n$$ defines an **ergodic** Markov chain, then as $$n \rightarrow \infty$$, the generated samples distribution asymptoticly converges to the data generating distribution $$P(X)$$.

**Corollary 1** If the support for both $$P(X)$$ and $$P_\theta(X\lvert \tilde{X})$$ are contained in and non-zero in a finite-volume region, then $$T_n$$ will be ergodic.

**Corollary 2** If the support for $$P(X)$$ is contained in and non-zero in a finite-volume region $$V$$, which is fully connected, and for some $$\epsilon > 0$$ and $$\forall X, \tilde{X} \in V$$ with distance less than $$\epsilon$$, $$C(\tilde{X} \lvert X) > 0$$ and $$P(X \lvert \tilde{X}) > 0$$ then $$T_n$$ will be ergodic.

**Theorem 2** Let $$(H_t, X_t)_{t=0}^{\infty}$$ be the Markov chain defined by the following graphical model.

![]({{site.baseurl}}/public/img/reading/gsn-gm.png){:.center}

If we assume a stationay distribution, and for each value of $$(x, h)$$, we have that:

- all the $$P(X_t = x \lvert H_t = h) = g(x, h)$$ share the same density for $$ t \geq 1 $$.
- all the $$P(H_{t+1} = h \lvert H_t = h^\prime, X_t = x) = f(h, h^\prime, x)$$ share the same density for $$t \geq 0$$.
- $$P(H_0 = h \lvert X_0 = x) = P(H_1 = h \lvert X_0 = x)$$.
- $$P(X_1 = x \lvert H_1 = h) = P(X_0 = x\lvert H_1 =  h)$$.

then for every value of $$(x, h)$$ 

- $$P(X_0 = x \lvert H_0 = h) = g(x, h)$$.
- $$P(X_t = x, H_t = h) = P(X_0 = x, H_0 = h)$$ for all $$ t \geq 0$$.
- The stationary distribution has a marginal distribution of $$P(X_0 = x)$$.

One limitation of this work is that the mode assumption restrict the space to be mainly local around training samples. The stochastic operator explored space starting from and primarily centered around training samples, and learned based on inputs in these parts of space only.