Deep conditional generative models are developed to simultaneously learn the temporal dependencies of multiple sequences. The model is designed by introducing a three-way weight tensor to capture the multiplicative interactions between side information and sequences. The proposed model builds on the Temporal Sigmoid Belief Network (TSBN), a sequential stack of Sigmoid Belief Networks (SBNs). The proposed weight tensor is further factored to reduce the number of
parameters and improve generalization. When side information si not available, a general framework for semi-superviesd learning based on the proposed model is consittuted, allowing robust sequences classification. Experimental results show that the proposed apporach achieves state-of-the-art predictive and classification performance on sequential data, and has the capacity to synthesize sequences, with controlled style transitioning and blending.
